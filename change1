import pandas as pd
import re
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder

# Load the Excel file
file_path = 'path_to_your_excel_file.xlsx'
df = pd.read_excel(file_path)

# Filter to include only 'Incident' and 'Catalog' ticket types
df = df[df['ticket_type'].isin(['Incident', 'Catalog'])]

# Preprocess the descriptions
def preprocess_description(description):
    description = description.lower()  # Convert to lowercase
    description = re.sub(r'\d+', '', description)  # Remove numbers
    description = re.sub(r'\W+', ' ', description)  # Remove special characters
    description = description.strip()  # Remove leading and trailing spaces
    return description

df['cleaned_description'] = df['ticket description'].apply(preprocess_description)

# Define the keywords and their respective categories
categories = {
    'Hadoop': ['hadoop'],
    'Firewall': ['firewall'],
    'Access': ['read', 'write'],
    'Alert - Space': ['cloudview', 'space'],
    'Alert - Memory/Swap': ['cloudview', 'memory/swap'],
    'Alert - Memory': ['cloudview', 'memory'],
    'Alert - Out of Memory': ['cloudview', 'out of memory']
}

# Label the data based on keywords
def label_data(description):
    for category, keywords in categories.items():
        if any(keyword in description for keyword in keywords):
            return category
    return 'General classification'

df['Category'] = df['cleaned_description'].apply(label_data)

# Count the number of 'General classification' descriptions
general_classification_count = df[df['Category'] == 'General classification'].shape[0]
print(f"Number of general descriptions: {general_classification_count}")

# Prepare the features and labels
X = df['cleaned_description']
y = df['Category']

# Encode labels
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Stratified Shuffle Split
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(X, y_encoded):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y_encoded[train_index], y_encoded[test_index]

# Create a text processing and classification pipeline
model = make_pipeline(TfidfVectorizer(stop_words='english'), MultinomialNB())

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Output the classification report
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Classify the whole dataset
df['Predicted Category'] = label_encoder.inverse_transform(model.predict(X))

# Select only the required columns for the output
output_df = df[['ticket_number', 'ticket description', 'Category', 'Predicted Category']]

# Save the results to a new Excel file
output_file_path = 'classified_tickets.xlsx'
output_df.to_excel(output_file_path, index=False)

print(f"Classification completed. The results are saved in '{output_file_path}'")
